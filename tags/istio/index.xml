<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Istio on 广阔天地大有作为</title>
    <link>https://zhiqli.github.io/tags/istio/</link>
    <description>Recent content in Istio on 广阔天地大有作为</description>
    <generator>Hugo</generator>
    <language>zh</language>
    <copyright>© Copyright zhiqli</copyright>
    <lastBuildDate>Fri, 10 May 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://zhiqli.github.io/tags/istio/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>istio/envoy流量控制问题</title>
      <link>https://zhiqli.github.io/2019/05/istio/envoy%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      <guid>https://zhiqli.github.io/2019/05/istio/envoy%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E9%97%AE%E9%A2%98/</guid>
      <description>最近在调研istio，很重要的一点是想利用istio金丝雀发布时精细的流量控制。我们知道在k8s的金丝雀发布一般是通过label来控制，如果需要灰度1%的流量，那么总共需要100个pod。具体可以参考这篇文章。而istio则可以通过VirtualService来做流量控制，具体可以参考官方文档。&#xA;结论是暂时istio无法满足我们的需求，还是在这里记录一下调研过程。&#xA;背景 先说下我们的服务架构，api-gateway和服务之间是采用grpc长连接，想要控制api-gatewasy与服务之间的流量。 服务的架构如下&#xA;istio流量控制 流量拆分具体案例参考官方例子采用istio部署以后，部署VirutalService配置如下&#xA;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reporter-vs namespace: istio spec: hosts: - reporter http: - route: - destination: host: reporter subset: v1 weight: 90 - destination: host: reporter subset: v2 weight: 10 --- apiVersion: networking.</description>
    </item>
    <item>
      <title>istio 抓取应用程序的metric</title>
      <link>https://zhiqli.github.io/2019/05/istio-%E6%8A%93%E5%8F%96%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84metric/</link>
      <pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate>
      <guid>https://zhiqli.github.io/2019/05/istio-%E6%8A%93%E5%8F%96%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84metric/</guid>
      <description>istio中会对网格内数据的metric数据收集，也可以自定义一些新的metric。通过这些数据有助于了解流量如何在集群中流动的。但这些数据不包括应用程序业务层的数据。 我们的应用中都有调用prometheus的go client api统计一些业务层的数据，由应用服务暴露一个端口。这些应用层的数据抓取当然可以起一个独立的prometheus服务，在istio1.1中，也可以使用istio的prometheus来收集。 本文主要记录采用istio prometheus抓取数据的配置。&#xA;配置 在文档中没有提及抓取收集应用程序metrics，这个描述是在FAQ中，Istio / Metrics and Logs FAQ。在install/kubernetes/istio-demo.yaml或install/kubernetes/istio-demo-auth.yaml的prometheus ConfigMap配置中有两个job&#xA;1 2 3 4 5 6 7 - job_name: &amp;#39;kubernetes-pods&amp;#39; kubernetes_sd_configs: - role: pod ..... - job_name: &amp;#39;kubernetes-pods-istio-secure&amp;#39; scheme: https 在没有启用mutual TLS 的环境中，job kubernetes-pods会从 Pod 中收集应用的metric。如果 Istio 启用了mutual TLS，就由job kubernetes-pods-istio-secure完成应用metric的收集工作。 这两个job都需要在pod yaml中添加annotations&#xA;1 2 3 prometheus.io/scrape: &amp;#34;true&amp;#34; prometheus.io/path: &amp;#34;&amp;lt;metrics path&amp;gt;&amp;#34; prometheus.io/port: &amp;#34;&amp;lt;metrics port&amp;gt;&amp;#34; 应用 OK，查完文档，开始实践。我的环境没有开启mutual TLS 。 服务起来以后查看prometheus target，奇怪的事情发生了&#xA;我的服务在kubernetes-pods-istio-secure job下，而在这个job下指定了scheme为https。由于没有配置https，访问不通。 经过一番google还是没有找到问题，后面看到kubernetes-pods的配置里面有一个source_labels: [__meta_kubernetes_pod_annotation_sidecar_istio_io_status, __meta_kubernetes_pod_annotation_prometheus_io_scheme]于是在pod yaml annotations增加Prometheus.io/scheme: &amp;quot;http&amp;quot; 再次刷新网页，我的3个应用出现在kubernetes-pods，状态也为UP。</description>
    </item>
  </channel>
</rss>
